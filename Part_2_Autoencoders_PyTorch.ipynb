{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPsIO-Li2KNf"
      },
      "source": [
        "# Autoencoder with Convolutions\n",
        "\n",
        "### Background Dataset  : CIFAR10\n",
        "* Training Images : 50000\n",
        "* Testing Images : 10000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B73JfqqU2KNg"
      },
      "source": [
        "### **1.Load Libraries**\n",
        "\n",
        "The imported modules include:\n",
        "\n",
        "* `torchvision`: contains many popular computer vision datasets, deep neural network architectures, and image processing modules. We will use this to download the CIFAR10 dataset.\n",
        "* `torch.nn`: contains the deep learning neural network layers such as `Linear()`, and `Conv2d()`.\n",
        "* `transforms`: will help in defining the image transforms and normalizations.\n",
        "* `optim`: contains the deep learning optimizer classes such as `MSELoss()` and many others as well.\n",
        "* `functional`: we will use this for activation functions such as ReLU.\n",
        "* `DataLoader`: eases the task of making iterable training and testing sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I8XtK8Z_2KNh"
      },
      "outputs": [],
      "source": [
        "# Loading torch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "# Loading torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import save_image\n",
        "import torchvision.datasets as dsets\n",
        "from torchsummary import summary\n",
        "\n",
        "# Loading other packages\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YkPtHFf2KNh"
      },
      "source": [
        "### **2. Defining the Constants**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "djTiBZuK2KNi"
      },
      "outputs": [],
      "source": [
        "NUM_EPOCHS = 10\n",
        "LEANRING_RATE = 0.001\n",
        "BATCH_SIZE = 128"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKoAXxi52KNi"
      },
      "source": [
        "### **3.Preparing the Data and Load in Data Loader**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WfGZv7Nx2KNi"
      },
      "outputs": [],
      "source": [
        "transforms = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJzLxVUd2KNj",
        "outputId": "d776a692-7b0a-4799-eee8-04a50c72316b"
      },
      "outputs": [],
      "source": [
        "# Download CIFAR10 dataset\n",
        "trainset = dsets.CIFAR10(root='./data_cifar10', train=True, download=True, transform=transforms)\n",
        "testset = dsets.CIFAR10(root='./data_cifar10', train=False, download=True, transform=transforms)\n",
        "\n",
        "# Data loader\n",
        "trainLoader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "testLoader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzSPjQUl2KNj"
      },
      "source": [
        "### **4.Some Helper functions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JIvkgkEa2KNj"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define the\n",
        "def make_dir():\n",
        "    image_dir = './image_cifar10/'\n",
        "    if not os.path.exists(image_dir):\n",
        "        os.mkdir(image_dir)\n",
        "\n",
        "# save decoded images\n",
        "def save_decoded_image(img, name):\n",
        "    img = img.view(img.size(0), 3, 32, 32)\n",
        "    save_image(img, './image_cifar10/' + name + '.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8nTIXrz2KNk"
      },
      "source": [
        "We have three functions in the above code snippet. Letâ€™s take a look at each of them.\n",
        "\n",
        "- `get_device()`: this function returns the computation device. That is, it will return either the CUDA GPU device if present, or the CPU.\n",
        "- `make_dir()`: this will make a directory named Conv_CIFAR10_Images. We will save the original and decoded images in this directory while training the neural network.\n",
        "- `save_decoded_image()`: this is a very simple function that will save the images in the Conv_CIFAR10_Images directory."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCYiwuSF2KNk"
      },
      "source": [
        "### **5.Defining AutoEncoder Neural Network**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDu6isCy2KNk",
        "outputId": "be2e608a-b0e1-4d35-9cab-bf5567653964"
      },
      "outputs": [],
      "source": [
        "class AutoEncoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(AutoEncoder, self).__init__()\n",
        "\n",
        "        # encoder\n",
        "        self.enc1 = nn.Conv2d(3, 8, 3) # First Ecnoder Layer\n",
        "        self.enc2 = nn.Conv2d(8, 4, 3) # Second Encoder Layer\n",
        "\n",
        "        # decoder\n",
        "        self.dec1 = nn.ConvTranspose2d(4, 8, 3) # First Decoder Layer\n",
        "        self.dec2 = nn.ConvTranspose2d(8, 3, 3) # Second Decoder Layer\n",
        "\n",
        "    # Rectified Linear Unit\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.enc1(x))\n",
        "        x = F.relu(self.enc2(x))\n",
        "        x = F.relu(self.dec1(x))\n",
        "        x = F.relu(self.dec2(x))\n",
        "        return x\n",
        "\n",
        "model = AutoEncoder().to(device)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aIx9q-o2KNk"
      },
      "source": [
        "### **6.Loss Function and Optimizer**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sTsGsymx2KNk"
      },
      "outputs": [],
      "source": [
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr= LEANRING_RATE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrAkVJu52KNk"
      },
      "source": [
        "### **7.Defining Training and Testing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MzZ17oFP2KNk"
      },
      "outputs": [],
      "source": [
        "def train(net, trainloader, NUM_EPOCHS):\n",
        "    train_loss = []\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        start = time.time()\n",
        "        running_loss = 0.0\n",
        "        for data in trainloader:\n",
        "            img, _ = data # no need for the labels\n",
        "            img = img.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net(img)\n",
        "            loss = criterion(outputs, img)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        loss = running_loss / len(trainloader)\n",
        "        train_loss.append(loss)\n",
        "        end = time.time()\n",
        "        total_time = end - start\n",
        "        print('- Epoch {} of {}, ETA: {:.2f} Train Loss: {:.3f}'.format(\n",
        "            epoch+1, NUM_EPOCHS, total_time, loss))\n",
        "\n",
        "        if epoch % 5 == 0:\n",
        "            save_decoded_image(img.cpu().data, name='original{}'.format(epoch))\n",
        "            save_decoded_image(outputs.cpu().data, name='decoded{}'.format(epoch))\n",
        "    return train_loss\n",
        "def test_image_reconstruction(net, testloader):\n",
        "     for batch in testloader:\n",
        "        img, _ = batch\n",
        "        img = img.to(device)\n",
        "        outputs = net(img)\n",
        "        outputs = outputs.view(outputs.size(0), 3, 32, 32).cpu().data\n",
        "        save_image(outputs, 'conv_cifar10_reconstruction.png')\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lP3eAgN2KNl"
      },
      "source": [
        "### **9. Model training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 651
        },
        "id": "j6nnNeVU2KNl",
        "outputId": "74969381-6027-4e1d-89d0-4f018c7df054"
      },
      "outputs": [],
      "source": [
        "model.to(device)\n",
        "make_dir()\n",
        "train_loss = train(model, trainLoader, NUM_EPOCHS)\n",
        "plt.figure()\n",
        "plt.plot(train_loss)\n",
        "plt.title('Train Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.savefig('conv_ae_cifar10_loss.png')\n",
        "test_image_reconstruction(model, testLoader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DYfIiuEk2KNl",
        "outputId": "374b24b5-9bb0-45e3-f78e-ed465f937b40"
      },
      "outputs": [],
      "source": [
        "import matplotlib.image as mpimg\n",
        "plt.figure(figsize=(10,20))\n",
        "img = mpimg.imread(\"conv_cifar10_reconstruction.png\")\n",
        "plt.imshow(img)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
